OpenCL Performance Prediction using Architecture-Independent Features
---------------------------------------------------------------------

These are the artefacts associated with the paper "OpenCL Performance Prediction using Architecture-Independent Features" published in the proceedings for The 2018 International Conference on High Performance Computing & Simulation (HPCS 2018) in the International Workshop on High Performance and Dynamic Reconfigurable Systems and Networks (DRSN-2018) and was presented in Orleans, France 16-20 July 2018.

This artefact optionally uses binder -- automatic cloud hosting of Jupyter workbooks with support for docker.
So if you want to avoid all the steps mentioned below, simply click the binder badge.

[![Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/BeauJoh/opencl-predictions-with-aiwc/master/OpenCL\ Performance\ Prediction\ using\ Architecture-Independent\ Features.ipynb
)

# Installation

This project uses Docker to facilitate reproducibility. As such, it has the following dependencies:

* Docker -- available [here](https://docs.docker.com/install/linux/docker-ce/ubuntu/)

Optional Dependencies:

* Cuda 9.0 Runtime -- available [here](https://developer.nvidia.com/cuda-downloads)
* nvidia-docker2, install instructions found [here](https://github.com/NVIDIA/nvidia-docker)
* Docker nvidia container, installed with: `sudo apt install nvidia-container-runtime`

# Build

To generate a docker image named aiwc-prediction, run:

`docker build -t aiwc-prediction .`

# Run

To start the docker image run:

```
docker run --runtime=nvidia -it --mount src=`pwd`,target=/workspace,type=bind -p 8888:8888 --net=host aiwc-prediction
```

For reproducibility, BeakerX has also been added for replicating results and for the transparency of analysis.
To evaluate the artefact, launch jupyter with:

`beakerx --allow-root`

from within the container and following the prompts to access it from the website front-end.

*Note* that if this node is accessed from an ssh session local ssh port forwarding is required and is achieved with the following:

`ssh -N -f -L localhost:8888:localhost:8888 <node-name>`


Reproducibility
---------------

The model can be regenerated using the same set of tools on the provided data.

A reproduction of the model can be performed on the same sampled data as used in the published paper.
This is available as `data/full_dat.Rda`.

The model is regenerated by running `source('build_model.R')` from within `R`.
It can then be manipulated in `R` and is known as the `rgd.aiwc` variable.
Predictions can be made by adjusting the AIWC feature space, for instance of the test data set:

`x <- test_dat[1,] #make just one prediction by taking the first row of AIWC entries`

`x$device <- 'gtx1080' #change the AIWC feature space -- in this instance by changing the device from xeon_es-2697v2 to gtx1080`

`y <- predict(rgd.aiwc,type='response',data=x) #make a prediction`

`y$predictions #see the prediction for a CPU device`

Alternatively, generating a different sample the collected data is achieved by first by uncompressing the tarballs. The AIWC feature-spaces are extracted with:

`
cd data/feat_data/archive
python extract.py
`

The run-time data are extracted with:

`
cd data/time_data
tar -xvf all_times.tar
`

Finally, the data manipulations to bind the AIWC metrics -- predictor variables -- to the collected runtime results -- response variables -- and a sub-sampling is achieved by then launching `R`, in the `codes` directory, and executing the following R command:

`
cd codes
source(sample_generator.R')
`

Dependencies
------------

* R -- installed with `apt install r-base`
* ranger -- installed with `R CMD INSTALL ranger`
* git-lsf -- installed with:

~~~~
    wget https://github.com/git-lfs/git-lfs/releases/download/v2.5.1/git-lfs-linux-amd64-v2.5.1.tar.gz \
    tar -xvf git-lfs-linux-amd64-v2.5.1.tar.gz\
    ./install.sh\
    git lfs install
~~~~

Questions?
----------

If you have any questions about the paper, found [here](), the model, or the resulting predictions, please contact [me](mail:beau.johnston@anu.edu.au).
I'd like to hear your feedback and collaborate!

